import requests
from bs4 import BeautifulSoup
from loguru import logger

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
HEADERS = {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
}


def fetch_tgstat_html(url):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã TGStat —á–µ—Ä–µ–∑ requests."""
    try:
        logger.info(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º GET-–∑–∞–ø—Ä–æ—Å –Ω–∞ {url}...")
        response = requests.get(url, headers=HEADERS, timeout=10)

        if response.status_code == 200:
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–∏–ª–∏ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É.")
            return response.text
        else:
            logger.warning(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {response.status_code}")
            return None
    except requests.RequestException as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
        return None


def parse_tgstat(html):
    """–ü–∞—Ä—Å–∏—Ç HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã TGStat –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏."""
    soup = BeautifulSoup(html, "html.parser")
    stats = {}

    try:
        # –ü–æ–¥–ø–∏—Å—á–∏–∫–∏
        subscribers = soup.find(string="–ü–û–î–ü–ò–°–ß–ò–ö–ò")
        if subscribers:
            stats["subscribers"] = subscribers.find_next("h2").text.strip()
            logger.info(f"üìä –ü–æ–¥–ø–∏—Å—á–∏–∫–∏: {stats['subscribers']}")

        # –°—Ä–µ–¥–Ω–∏–π –æ—Ö–≤–∞—Ç
        avg_views = soup.find(string="–°–†–ï–î–ù–ò–ô –û–•–í–ê–¢")
        if avg_views:
            stats["average_views"] = avg_views.find_next("h2").text.strip()
            logger.info(f"üìä –°—Ä–µ–¥–Ω–∏–π –æ—Ö–≤–∞—Ç: {stats['average_views']}")

        # ERR (–≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å)
        err = soup.find(string="–í–û–í–õ–ï–ß–ï–ù–ù–û–°–¢–¨ –ü–û–î–ü–ò–°–ß–ò–ö–û–í (ERR)")
        if err:
            stats["engagement_rate"] = err.find_next("h2").text.strip()
            logger.info(f"üìä ERR: {stats['engagement_rate']}")

        # –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è
        creation_date = soup.find(string="–∫–∞–Ω–∞–ª —Å–æ–∑–¥–∞–Ω")
        if creation_date:
            stats["creation_date"] = creation_date.find_next("h2").text.strip()
            logger.info(f"üìä –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {stats['creation_date']}")

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
        posts_count = soup.find(string="–ü–£–ë–õ–ò–ö–ê–¶–ò–ò")
        if posts_count:
            stats["posts_count"] = posts_count.find_next("h2").text.strip()
            logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {stats['posts_count']}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")

    return stats


def get_tgstat_channel_stats_requests(channel_url):
    html_content = fetch_tgstat_html(channel_url)
    tgstat_data = None
    if html_content:
        tgstat_data = parse_tgstat(html_content)
        logger.info(f"üîé –ò—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {tgstat_data}")
    return tgstat_data
